---
---

@string{aps = {American Physical Society,}}



@article{jeantet_combined_2018,
  title = {Combined use of two supervised learning algorithms to model sea turtle behaviours from tri-axial acceleration data},
  author = {Jeantet, L. and Dell'Amico, F. and Forin-Wiart, M. A. and Coutant, M. and Bonola, M. and Etienne, D. and Gresser, J. and Regis, S. and Lecerf, N. and Lefebvre, F. and De Thoisy, B. and Le Maho, Y. and Brucker, M. and Châtelain, N. and Laesser, R. and Crenner, F. and Handrich, Y. and Wilson, R. and Chevallier, D.},
  year = {2018},
  abbr={JEB},
  bibtex_show={true},
  abstract = {Accelerometers are becoming ever more important sensors in animalattached technology, providing data that allow determination of body posture and movement and thereby helping to elucidate behaviour in animals that are difficult to observe. We sought to validate the identification of sea turtle behaviours from accelerometer signals by deploying tags on the carapace of a juvenile loggerhead (Caretta caretta), an adult hawksbill (Eretmochelys imbricata) and an adult green turtle (Chelonia mydas) at Aquarium La Rochelle, France. We recorded tri-axial acceleration at 50 Hz for each species for a full day while two fixed cameras recorded their behaviours. We identified behaviours from the acceleration data using two different supervised learning algorithms, Random Forest and Classification And Regression Tree ({CART}), treating the data from the adult animals as separate from the juvenile data. We achieved a global accuracy of 81.30\% for the adult hawksbill and green turtle {CART} model and 71.63\% for the juvenile loggerhead, identifying 10 and 12 different behaviours, respectively. Equivalent figures were 86.96\% for the adult hawksbill and green turtle Random Forest model and 79.49\% for the juvenile loggerhead, for the same behaviours. The use of Random Forest combined with {CART} algorithms allowed us to understand the decision rules implicated in behaviour discrimination, and thus remove or group together some ‘confused’ or under-represented behaviours in order to get the most accurate models. This study is the first to validate accelerometer data to identify turtle behaviours and the approach can now be tested on other captive sea turtle species.},
  html = {https://journals.biologists.com/jeb/article/doi/10.1242/jeb.177378/262989/Combined-use-of-two-supervised-learning-algorithms},
  doi = {10.1242/jeb.177378},
  pdf={jeantetetal2018.pdf},
  journal={Journal of Experimental Biology},
  volume={221},
  dimensions={true},
  selected={true},
  }

@article{jeantet_behavioural_2020,
	title = {Behavioural inference from signal processing using animal-borne multi-sensor loggers: a novel solution to extend the knowledge of sea turtle ecology},
	volume = {7},
  abbr={R. Soc. Open Sci.},
	issn = {2054-5703},
	html = {https://royalsocietypublishing.org/doi/10.1098/rsos.200139},
	doi = {10.1098/rsos.200139},
	abstract = {The identification of sea turtle behaviours is a prerequisite to predicting the activities and time-budget of these animals in their natural habitat over the long term. However, this is hampered by a lack of reliable methods that enable the detection and monitoring of certain key behaviours such as feeding. This study proposes a combined approach that automatically identifies the different behaviours of free-ranging sea turtles through the use of animal-borne multi-sensor recorders (accelerometer, gyroscope and time-depth recorder), validated by animal-borne video-recorder data. We show here that the combination of supervised learning algorithms and multi-signal analysis tools can provide accurate inferences of the behaviours expressed, including feeding and scratching behaviours that are of crucial ecological interest for sea turtles. Our procedure uses multi-sensor miniaturized loggers that can be deployed on free-ranging animals with minimal disturbance. It provides an easily adaptable and replicable approach for the long-term automatic identification of the different activities and determination of time-budgets in sea turtles. This approach should also be applicable to a broad range of other species and could significantly contribute to the conservation of endangered species by providing detailed knowledge of key animal activities such as feeding, travelling and resting.},
	pages = {200139},
	number = {5},
    bibtex_show={true},
	journal = {Royal Society Open Science},
	author = {Jeantet, L. and Planas-Bielsa, V. and Benhamou, S. and Geiger, S. and Martin, J. and Siegwalt, F. and Lelong, P. and Gresser, J. and Etienne, D. and Hiélard, G. and Arque, Alexandre and Regis, S. and Lecerf, N. and Frouin, C. and Benhalilou, A. and Murgale, C. and Maillet, T. and Andreani, L. and Campistron, G. and Delvaux, H. and Guyon, C. and Richard, S. and Lefebvre, F. and Aubert, N. and Habold, C. and le Maho, Y.n and Chevallier, D.},
	year = {2020},
	pdf={jeantetetal2020.pdf}
}

@article{Jeantet2021,
	title = {Fully convolutional neural network : a solution to infer animal behaviours from multi-sensor data},
	volume = {450},
	doi = {10.1016/j.ecolmodel.2021.109555},
	number = {109555},
	journal = {Ecological Modelling},
	author = {Jeantet, L. and Vigon, V. and Geiger, S. and Chevallier, D.},
	year = {2021},
	html={https://www.sciencedirect.com/science/article/abs/pii/S0304380021001253},
	abstract={Artificial neural networks are powerful supervised learning algorithms that are based on deep learning and have been poorly exploited in movement ecology.In this study, we adapt a fully convolutional neural network that was originally developed for biomedical 3D image segmentation: the V-net. We test it on a labelled dataset collected from animal-borne video recorders combined with multi-sensors (accelerometers, gyroscopes and depth recorders) deployed on free-ranging immature green turtles (Chelonia mydas). The proposed model, fitted for 1D data, is able to predict six behavioural categories for green turtles with an AUC score of 88%. Thus, diverted from its initial purpose and tested on sea turtle, the V-net is a very efficient method of behavioural identification that should be easily generalized to a wide range of species.},
	abbr={Ecol. Model.},
	dimensions={true},
    selected={true},
	bibtex_show={true},
	pdf={jeantetetal2021.pdf}

}

@article{debache_lean_2020,
	title = {A lean and performant hierarchical model for human activity recognition using body-mounted sensors},
	volume = {20},
	issn = {14248220},
	doi = {10.3390/s20113090},
	abstract = {Here we propose a new machine learning algorithm for classification of human activities by means of accelerometer and gyroscope signals. Based on a novel hierarchical system of logistic regression classifiers and a relatively small set of features extracted from the filtered signals, the proposed algorithm outperformed previous work on the {DaLiAc} (Daily Life Activity) and {mHealth} datasets. The algorithm also represents a significant improvement in terms of computational costs and requires no feature selection and hyper-parameter tuning. The algorithm still showed a robust performance with only two (ankle and wrist) out of the four devices (chest, wrist, hip and ankle) placed on the body (96.8\% vs. 97.3\% mean accuracy for the {DaLiAc} dataset). The present work shows that low-complexity models can compete with heavy, inefficient models in classification of advanced activities when designed with a careful upstream inspection of the data.},
	number = {11},
	journal = {Sensors},
	author = {Debache, I. and Jeantet, L. and Chevallier, D. and Bergouignan, A. and Sueur, C.},
	year = {2020},
	html={https://www.mdpi.com/1424-8220/20/11/3090},
	pdf={debacheetal2020.pdf},
	abbr={Sensors},
	dimensions={true},
	bibtex_show={true},
}

@article{bonola_fine_2019,
	title = {Fine scale geographic residence and annual primary production drive body condition of wild immature green turtles (Chelonia mydas) in Martinique Island (Lesser Antilles)},
	volume = {8},
	issn = {20466390},
	doi = {10.1242/bio.048058},
	abstract = {The change of animal biometrics (body mass and body size) can reveal important information about their living environment as well as determine the survival potential and reproductive success of individuals and thus the persistence of populations. However, weighing individuals like marine turtles in the field presents important logistical difficulties. In this context, estimating body mass ({BM}) based on body size is a crucial issue. Furthermore, the determinants of the variability of the parameters for this relationship can provide information about the quality of the environment and the manner in which individuals exploit the available resources. This is of particular importance in young individuals where growth quality might be a determinant of adult fitness. Our study aimed to validate the use of different body measurements to estimate {BM}, which can be difficult to obtain in the field, and explore the determinants of the relationship between {BM} and size in juvenile green turtles. Juvenile green turtles were caught, measured, and weighed over 6 years (2011–2012; 2015–2018) at six bays to the west of Martinique Island (Lesser Antilles). Using different datasets from this global database, we were able to show that the {BM} of individuals can be predicted from body measurements with an error of less than 2\%. We built several datasets including different morphological and time-location information to test the accuracy of the mass prediction. We show a yearly and north–south pattern for the relationship between {BM} and body measurements. The year effect for the relationship of {BM} and size is strongly correlated with net primary production but not with sea surface temperature or cyclonic events. We also found that if the bay locations and year effects were removed from the analysis, the mass prediction degraded slightly but was still less than 3\% on average. Further investigations of the feeding habitats in Martinique turtles are still needed to better understand these effects and to link them with geographic and oceanographic conditions.},
	number = {12},
	year={2019},
	journal = {Biology Open},
	author = {Bonola, Marc and Girondot, Marc and Robin, Jean Patrice and Martin, Jordan and Siegwalt, Flora and Jeantet, Lorene and Lelong, Pierre and Grand, Clément and Chambault, Philippine and Etienne, Denis and Gresser, Julie and Hielard, Gaëlle and Arqué, Alexandre and Régis, Sidney and Lecerf, Nicolas and Frouin, Cédric and Lefebvre, Fabien and Sutter, Emmanuel and Vedie, Fabien and Barnerias, Cyrille and Thieulle, Laurent and Bordes, Robinson and Guimera, Christelle and Aubert, Nathalie and Bouaziz, Myriam and Pinson, Adrien and Flora, Frédéric and Duru, Matthieu and Benhalilou, Abdelwahab and Murgale, Céline and Maillet, Thomas and Andreani, Lucas and Campistron, Guilhem and Sikora, Maxym and Rateau, Fabian and George, Francis and Eggenspieler, Joffrey and Woignier, Thierry and Allenou, Jean Pierre and Louis-Jean, Laurent and Chanteur, Bénédicte and Béranger, Christelle and Crillon, Jessica and Brador, Aude and Habold, Caroline and Le Maho, Yvon and Chevallier, Damien},
	html={https://journals.biologists.com/bio/article/8/12/bio048058/222968/Fine-scale-geographic-residence-and-annual-primary},
	pdf={bonolaetal2019.pdf},
	abbr={Biol. Open},
	dimensions={true},
	bibtex_show={true},
	}



@article{siegwalt_high_2020,
	title = {High fidelity of sea turtles to their foraging grounds revealed by satellite tracking and capture-mark-recapture: New insights for the establishment of key marine conservation areas.},
	volume = {250},
	issn = {0006-3207},
	html = {https://www.sciencedirect.com/science/article/abs/pii/S0006320720308004},
	doi = {10.1016/j.biocon.2020.108742},
	pages = {108742},
	issue = {July},
	journal = {Biological Conservation},
	author = {Siegwalt, Flora and Benhamou, Simon and Girondot, Marc and Jeantet, Lorène and Martin, Jordan and Bonola, Marc and Lelong, Pierre and Grand, Clément and Chambault, Philippine and Benhalilou, Abdelwahab and Murgale, Céline and Maillet, Thomas and Andreani, Lucas and Campistron, Guilhem and Jacaria, François and Hielard, Gaëlle and Arqué, Alexandre and Etienne, Denis and Gresser, Julie and Régis, Sidney and Lecerf, Nicolas and Frouin, Cédric and Lefebvre, Fabien and Aubert, Nathalie and Vedie, Fabien and Barnerias, Cyrille and Thieulle, Laurent and Guimera, Christelle and Bouaziz, Myriam and Pinson, Adrien and Flora, Frédéric and George, Francis and Eggenspieler, Joffrey and Woignier, Thierry and Allenou, Jean-Pierre and Louis-Jean, Laurent and Chanteur, Bénédicte and Béranger, Christelle and Crillon, Jessica and Brador, Aude and Habold, Caroline and Maho, Yvon Le and Robin, Jean-Patrice and Chevallier, Damien},
	year = {2020},
	pdf={siegwaltetal2020.pdf},
	abbr={Biol. Conserv.},
	dimensions={true},
	bibtex_show={true},

}

@article{charrier_first_2022,
	title = {First evidence of underwater vocalizations in green sea turtles Chelonia mydas},
	volume = {48},
	issn = {16134796},
	doi = {10.3354/esr01185},
	abstract = {Marine turtles have long been considered to be silent, but few investigations have been performed to confirm such muteness. However, recent studies on the aerial and underwater hearing abilities of marine turtles have shown they have an ability to perceive sounds, suggesting the potential existence of acoustic communication among them. In the present study, audio-video recorders were deployed on 11 free-ranging juvenile green sea turtles Chelonia mydas at Grande Anse d’Arlet in Martinique. The recordings revealed that the turtles produced 10 different sound types that were classified into 4 main categories: pulses, low-amplitude calls ({LAC}), frequencymodulated sounds, and squeaks. Although other turtles were not observed in close proximity to tagged turtles during the recordings, some of the described sounds were found in most recorded individuals and their frequency characteristics ranged within the underwater hearing range of green sea turtles, suggesting that the sounds could be used for intra-specific communication. While control recordings in the study area without the presence of green sea turtles contained sounds with similar general structure (pulses, {LAC}), the acoustic characteristics were significantly different to those recorded for green sea turtles. The 2 types of squeaks identified for the turtles were found to be individual-specific, also suggesting they could be used for intra-species communication. Further research on sea turtles is needed to better understand the behavioral and social context of these acoustic productions, especially during the developmental period and breeding season. Thus, the vocal repertoire of green sea turtles is likely to be more diverse than that currently described},
	pages = {31--41},
	journal = {Endangered Species Research},
	author = {Charrier, Isabelle and Jeantet, Lorène and Maucourt, Léo and Régis, Sidney and Lecerf, Nicolas and Benhalilou, Abdelwahab and Chevallier, Damien},
	year = {2022},
	html={https://www.int-res.com/abstracts/esr/v48/p31-41/},
	pdf={charrieretal2022.pdf},
	abbr={ESR},
	dimensions={true},
	bibtex_show={true},

}

@article{siegwalt_food_2022,
	title = {Food selection and habitat use patterns of immature green turtles (Chelonia mydas) on Caribbean seagrass beds dominated by the alien species Halophila stipulacea},
	volume = {37},
	issn = {23519894},
	doi = {10.1016/j.gecco.2022.e02169},
	pages = {e02169},
	issue = {May},
	journal = {Global Ecology and Conservation},
	author = {Siegwalt, Flora and Jeantet, Lorène and Lelong, Pierre and Martin, Jordan and Girondot, Marc and Bustamante, Paco and Benhalilou, Abdelwahab and Murgale, Céline and Andreani, Lucas and Jacaria, François and Campistron, Guilhem and Lathière, Anthony and Barotin, Charlène and Buret-Rochas, Gaëlle and Barre, Philippe and Hielard, Gaëlle and Arqué, Alexandre and Régis, Sidney and Lecerf, Nicolas and Frouin, Cédric and Lefebvre, Fabien and Aubert, Nathalie and Arthus, Mosiah and Etienne, Denis and Allenou, Jean-Pierre and Delnatte, César and Lafolle, Rachelle and Thobor, Florence and Chevallier, Pascale and Chevallier, Tao and Lepori, Muriel and Assio, Cindy and Grand, Clément and Bonola, Marc and Tursi, Yannick and Varkala, Pierre-Walter and Meslier, Stéphane and Landreau, Anthony and Le Maho, Yvon and Habold, Caroline and Robin, Jean-Patrice and Chevallier, Damien},
	year = {2022},
	html={https://www.sciencedirect.com/science/article/pii/S2351989422001718},
	pdf={siegwaltetal2022.pdf},
	abbr={GECCO},
	dimensions={true},
	bibtex_show={true},
}

@article{jeantet_estimation_2022,
	title = {Estimation of the Maternal Investment of Sea Turtles by Automatic Identification of Nesting Behavior and Number of Eggs Laid from a Tri-Axial Accelerometer},
	volume = {12},
	issn = {20762615},
	doi = {10.3390/ani12040520},
	abstract = {Monitoring reproductive outputs of sea turtles is difficult, as it requires a large number of observers patrolling extended beaches every night throughout the breeding season with the risk of missing nesting individuals. We introduce the first automatic method to remotely record the reproductive outputs of green turtles (Chelonia mydas) using accelerometers. First, we trained a fully convolutional neural network, the V-net, to automatically identify the six behaviors shown during nesting. With an accuracy of 0.95, the V-net succeeded in detecting the Egg laying process with a precision of 0.97. Then, we estimated the number of laid eggs from the predicted Egg laying sequence and obtained the outputs with a mean relative error of 7\% compared to the observed numbers in the field. Based on deployment of non-invasive and miniature loggers, the proposed method should help researchers monitor nesting sea turtle populations. Furthermore, its use can be coupled with the deployment of accelerometers at sea during the intra-nesting period, from which behaviors can also be estimated. The knowledge of the behavior of sea turtle on land and at sea during the entire reproduction period is essential to improve our knowledge of this threatened species.},
	number = {4},
	journal = {Animals},
	author = {Jeantet, Lorène and Hadetskyi, Vadym and Vigon, Vincent and Korysko, François and Paranthoen, Nicolas and Chevallier, Damien},
	year = {2022},
	html={https://www.mdpi.com/2076-2615/12/4/520},
	pdf={jeantetetal2022.pdf},
	abbr={Animals},
	dimensions={true},
	bibtex_show={true},
}

@article{roost_fibropapillomatosis_2022,
	title = {Fibropapillomatosis Prevalence and Distribution in Immature Green Turtles (Chelonia mydas) in Martinique Island (Lesser Antilles)},
	volume = {19},
	issn = {1612-9210},
	html = {https://link.springer.com/article/10.1007/s10393-022-01601-y},
	doi = {10.1007/s10393-022-01601-y},
	abstract = {Fibropapillomatosis ({FP}) threatens the survival of green turtle (Chelonia mydas) populations at a global scale, and human activities are regularly pointed as causes of high {FP} prevalence. However, the association of ecological factors with the disease’s severity in complex coastal systems has not been well established and requires further studies. Based on a set of 405 individuals caught over ten years, this preliminary study provides the first insight of {FP} in Martinique Island, which is a critical development area for immature green turtles. Our main results are: (i) 12.8\% of the individuals were affected by {FP}, (ii) {FP} has different prevalence and temporal evolution between very close sites, (iii) green turtles are more frequently affected on the upper body part such as eyes (41.4\%), fore flippers (21.9\%), and the neck (9.4\%), and (iv) high densities of individuals are observed on restricted areas. We hypothesise that turtle’s aggregation enhances horizontal transmission of the disease. {FP} could represent a risk for immature green turtles’ survival in the French West Indies, a critical development area, which replenishes the entire Atlantic population. Continuing scientific monitoring is required to identify which factors are implicated in this panzootic disease and ensure the conservation of the green turtle at an international scale.},
	pages = {190--202},
	number = {2},
	journal = {EcoHealth},
	author = {Roost, Thibaut and Schies, Jo-Ann and Girondot, Marc and Robin, Jean-Patrice and Lelong, Pierre and Martin, Jordan and Siegwalt, Flora and Jeantet, Lorène and Giraudeau, Mathieu and Le Loch, Guillaume and Bejarano, Manola and Bonola, Marc and Benhalilou, Abdelwahab and Murgale, Céline and Andreani, Lucas and Jacaria, François and Campistron, Guilhem and Lathière, Anthony and Martial, François and Hielard, Gaëlle and Arqué, Alexandre and Régis, Sidney and Lecerf, Nicolas and Frouin, Cédric and Lefebvre, Fabien and Aubert, Nathalie and Flora, Frédéric and Pimentel, Esteban and Lafolle, Rachelle and Thobor, Florence and Arthus, Mosiah and Etienne, Denis and Lecerf, Nathaël and Allenou, Jean-Pierre and Desigaux, Florian and Larcher, Eugène and Larcher, Christian and Curto, Alberto Lo and Befort, Joanne and Maceno-Panevel, Myriane and Lepori, Muriel and Chevallier, Pascale and Chevallier, Tao and Meslier, Stéphane and Landreau, Anthony and Habold, Caroline and Le Maho, Yvon and Chevallier, Damien},
	year = {2022},
	abbr={EcoHealth},
	dimensions={true},
	bibtex_show={true},

}


@article{jeantet_improving_2023,
	title = {Improving deep learning acoustic classifiers with contextual information for wildlife monitoring},
	volume = {77},
	issn = {15749541},
	doi = {10.1016/j.ecoinf.2023.102256},
	abstract = {Bioacoustics, the exploration of animal vocalizations and natural soundscapes, has emerged as a valuable tool for studying species within their habitats, particularly those that are challenging to observe. This approach has broadened the horizons of biodiversity assessment and ecological research. However, monitoring wildlife with acoustic recorders produces large volumes of data that can be labor-intensive to analyze. Deep learning has recently transformed many computational disciplines by enabling the automated processing of large and complex datasets and has gained attention within the bioacoustics community. Despite the revolutionary impact of deep learning on acoustic detection and classification, attaining both high detection accuracy and low false positive rates in bioacoustics remains a significant challenge. An intriguing yet unexplored avenue for enhancing deep learning in bioacoustics involves the utilization of contextual information, such as time and location, to discern animal vocalizations within acoustic recordings. As a first case study, a multi-branch Convolutional Neural Network ({CNN}) was developed to classify 22 different bird songs using spectrograms as a first input, and spatial metadata as a secondary input. A comparison was made to a baseline model with only spectrogram input. A geographical prior neural network was trained, separately, to estimate the probability of a species occurring at a given location. The output of this network was combined with the baseline {CNN}. As a second case study, temporal data and spectrograms were used as input to a multi-branch {CNN} for the detection of Hainan gibbon (Nomascus hainanus) calls, the world's rarest primate. Our findings demonstrate that adding metadata to the bird song classifier significantly improves classification performance, with the highest improvement achieved using the geographical prior model (F1-score of 87.78\% compared to 61.02\% for the baseline model). The multi-branch {CNNs} also proved efficient (F1-scores of 76.87\% and 78.77\%) and simpler to use than the geographical prior. In the second case study, our findings revealed a decrease in false positives by 63\% (94\% of the calls were detected) when the metadata was used by the multi-branch {CNN}, and an increase of 19\% in gibbon detection. This study has uncovered an exciting new avenue for improving classifier performance in bioacoustics. The methodology described in this study can assist ecologists, wildlife management teams, and researchers in reducing the amount of time spent analyzing large acoustic datasets obtained from passive acoustic monitoring studies. Our approach can be adapted and applied to other calling species, and thus tailored to other use cases.},
	journal = {Ecological Informatics},
	author = {Jeantet, Lorène and Dufourq, Emmanuel},
	year = {2023},
	html={https://www.sciencedirect.com/science/article/pii/S1574954123002856},
	pdf={jeantetetal2023.pdf},
	abbr={Ecol. Inform.},
	dimensions={true},
	bibtex_show={true},
}

@article{batist_integrated_2024,
	title = {An integrated passive acoustic monitoring and deep learning pipeline for black-and-white ruffed lemurs (Varecia variegata) in Ranomafana National Park, Madagascar},
	issn = {10982345},
	doi = {10.1002/ajp.23599},
	abstract = {The urgent need for effective wildlife monitoring solutions in the face of global biodiversity loss has resulted in the emergence of conservation technologies such as passive acoustic monitoring ({PAM}). While {PAM} has been extensively used for marine mammals, birds, and bats, its application to primates is limited. Black-and-white ruffed lemurs (Varecia variegata) are a promising species to test {PAM} with due to their distinctive and loud roar-shrieks. Furthermore, these lemurs are challenging to monitor via traditional methods due to their fragmented and often unpredictable distribution in Madagascar's dense eastern rainforests. Our goal in this study was to develop a machine learning pipeline for automated call detection from {PAM} data, compare the effectiveness of {PAM} versus in-person observations, and investigate diel patterns in lemur vocal behavior. We did this study at Mangevo, Ranomafana National Park by concurrently conducting focal follows and deploying autonomous recorders in May–July 2019. We used transfer learning to build a convolutional neural network (optimized for recall) that automated the detection of lemur calls (57-h runtime; recall = 0.94, F1 = 0.70). We found that {PAM} outperformed in-person observations, saving time, money, and labor while also providing re-analyzable data. Using {PAM} yielded novel insights into V. variegata diel vocal patterns; we present the first published evidence of nocturnal calling. We developed a graphic user interface and open-sourced data and code, to serve as a resource for primatologists interested in implementing {PAM} and machine learning. By leveraging the potential of this pipeline, we can address the urgent need for effective primate population surveys to inform conservation strategies.},
	pages = {1--18},
	journal = {American Journal of Primatology},
	author = {Batist, Carly H. and Dufourq, Emmanuel and Jeantet, Lorène and Razafindraibe, Mendrika N. and Randriamanantena, Francois and Baden, Andrea L.},
	year = {2024},
	html={https://onlinelibrary.wiley.com/doi/10.1002/ajp.23599},
	pdf={batistetal2024.pdf},
	abbr={Am. J. Primatol.},
	dimensions={true},
	bibtex_show={true},
}